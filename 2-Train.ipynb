{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Boats from Space - Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install, Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various utilities\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import superintendent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import getImageSetDirectories, S2_Dataset, plot_dataset\n",
    "from src.model import Model\n",
    "from src.train import train, get_failures_or_success\n",
    "from src.annotation_utils import display_image_and_references, display_heatmap_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available() # gpu support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Init K-Fold Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/jovyan/data\" # data directory (path)\n",
    "labels_dir = './data'\n",
    "checkpoint_dir = \"/home/jovyan/checkpoints\"\n",
    "bands = ['img_08', 'bg_ndwi']\n",
    "test_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, val_list, fig = getImageSetDirectories(data_dir=os.path.join(data_dir, 'chips'), \n",
    "                                                   labels_filename=os.path.join(labels_dir, \"labels.csv\"),\n",
    "                                                   band_list=bands, test_size=test_size, plot_coords=False, plot_class_imbalance=True, seed=123)\n",
    "fig # mapbox plot train/val coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = S2_Dataset(imset_dir=train_list, augment=True, labels_filename=os.path.join(labels_dir,'labels.csv'))\n",
    "val_dataset = S2_Dataset(imset_dir=val_list, augment=False, labels_filename=os.path.join(labels_dir,'labels.csv'))\n",
    "plot_dataset(train_dataset, n_frames=14, n_rows=2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train PyTorch Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training config\n",
    "input_dim = train_dataset[0]['img'].shape[0]\n",
    "hidden_dim, kernel_size, pool_size, n_max = 16, 3, 10, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=16)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "best_metrics = train(train_dataloader=train_dataloader, val_dataloader=val_dataloader,\n",
    "             input_dim=input_dim, hidden_dim=hidden_dim, kernel_size=kernel_size, pool_size=pool_size, n_max=n_max, drop_proba=0.15,\n",
    "             ld=0.5, water_ndwi=0.4,\n",
    "             n_epochs=50, lr=0.007, lr_step=2, lr_decay=0.95,\n",
    "             device='cpu', checkpoints_dir=checkpoint_dir, seed=42, verbose=1, version='0.0.5')\n",
    "\n",
    "for k,v in best_metrics.items():\n",
    "    print('{} {:.4f}'.format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.0.4 Epoch 34: train_clf_error 0.06563 / train_reg_error 0.10578 / val_clf_error 0.04367 / val_reg_error 0.06262"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "model = Model(input_dim=input_dim, hidden_dim=hidden_dim, kernel_size=kernel_size, pool_size=pool_size, n_max=n_max, device='cpu', version='0.0.4')\n",
    "checkpoint_file = os.path.join(checkpoint_dir, model.folder, 'model.pth')\n",
    "model.load_checkpoint(checkpoint_file=checkpoint_file)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display failures (train, val), scatter plot (Predicted vs True) and inspect hidden channels --> Re label?\n",
    "image_titles, relabel_images = get_failures_or_success(model, val_dataset,success=None, filter_on=None,\n",
    "                                                       water_ndwi=0.5, filter_peaks=True, shift_pool=False, downsample=False,\n",
    "                                                       plot_heatmap=False, hidden_channel=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Relabel inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load superintendent widget and labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"/home/jovyan/data/labels.csv\"\n",
    "labels_df = pd.read_csv(csv_file_path, index_col = ['lat_lon', 'timestamp'], dtype={'count': float})\n",
    "\n",
    "labeller = superintendent.ClassLabeller(\n",
    "    features=image_titles,\n",
    "    options=[i for i in range(-1, 6)], \n",
    "    display_func=display_heatmap_prediction\n",
    ")\n",
    "\n",
    "#labeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract new labels and save them in labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(relabel_images)):\n",
    "    timestamp = relabel_images[i].stem.split('t_')[1]\n",
    "    lat_lon = relabel_images[i].parts[-2]\n",
    "    count = labeller.new_labels[i]\n",
    "    # overwrite if the \n",
    "    if count:\n",
    "        labels_df.at[(lat_lon, timestamp)] = count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump back to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_df.to_csv(csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
